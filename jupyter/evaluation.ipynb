{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:56:53.162832Z",
     "start_time": "2024-04-02T07:56:47.700384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM (First 1000)\n",
      "> Top1:\n",
      "\t177/1000 correct predictions\n",
      "\tAccuracy: 0.177\n",
      "\tEd: 8.298\n",
      "\tRed: 4.434797763347763\n",
      "\tGleu: 50.43027101817904\n",
      "\tMeteor: 71.51160847113778\n",
      "> Optimal Top5:\n",
      "\t255/1000 correct predictions\n",
      "\tAccuracy: 0.255\n",
      "\tEd: 4.518\n",
      "\tRed: 2.224820562770563\n",
      "\tGleu: 62.95210913858119\n",
      "\tMeteor: 80.96390942368838\n",
      "> Sort by rouge recall\n",
      "\t190/1000 correct predictions\n",
      "\tAccuracy: 0.19\n",
      "\tEd: 7.188\n",
      "\tRed: 3.6491228354978356\n",
      "\tGleu: 55.793363608427356\n",
      "\tMeteor: 77.5791608100043\n",
      "> Sort by rouge precision\n",
      "\t218/1000 correct predictions\n",
      "\tAccuracy: 0.218\n",
      "\tEd: 4.735\n",
      "\tRed: 2.329260461760462\n",
      "\tGleu: 60.33835548338917\n",
      "\tMeteor: 78.83147036027287\n",
      "> Sort by rouge ƒ1\n",
      "\t216/1000 correct predictions\n",
      "\tAccuracy: 0.216\n",
      "\tEd: 4.878\n",
      "\tRed: 2.392048556998557\n",
      "\tGleu: 60.31815696840139\n",
      "\tMeteor: 79.21078173363045\n",
      "> Sort by levenshtein distance\n",
      "\t224/1000 correct predictions\n",
      "\tAccuracy: 0.224\n",
      "\tEd: 4.276\n",
      "\tRed: 1.9742834054834055\n",
      "\tGleu: 60.65087004693572\n",
      "\tMeteor: 78.41884282500656\n",
      "> Sort by gleu\n",
      "\t223/1000 correct predictions\n",
      "\tAccuracy: 0.223\n",
      "\tEd: 4.866\n",
      "\tRed: 2.3705791847041846\n",
      "\tGleu: 60.695316951972615\n",
      "\tMeteor: 79.59581782504085\n"
     ]
    }
   ],
   "source": [
    "from sorter import *\n",
    "import statistics\n",
    "\n",
    "import eval\n",
    "\n",
    "\n",
    "def evaluate(result_array):\n",
    "    stats_dict = {}\n",
    "    for metric in metrics:\n",
    "        avg = statistics.mean(map(lambda line: line[metric], result_array))\n",
    "        stats_dict[metric] = avg\n",
    "    nr_correct = len(list(filter(lambda line: line['ed'] == 0, result_array)))\n",
    "    stats_dict['accuracy'] = nr_correct / len(result_array)\n",
    "    print(f'\\t{nr_correct}/{len(result_array)} correct predictions')\n",
    "\n",
    "    return stats_dict\n",
    "\n",
    "def print_all_metrics(d):\n",
    "    for metric in metrics1:\n",
    "        print(f'\\t{metric.capitalize()}: {d[metric]}')\n",
    "\n",
    "\n",
    "metrics = ['ed', 'red', 'gleu', 'meteor']\n",
    "metrics1 = ['accuracy'] + metrics\n",
    "\n",
    "#Baseline\n",
    "\n",
    "# ## CUP (First 1000)\n",
    "# print('CUP (First 1000)')\n",
    "# cup_result = eval.evaluate('../result/baseline/CUP_first1000.jsonl', 'CUP')[:1000]\n",
    "# cup_d = evaluate(cup_result)\n",
    "# print_all_metrics(cup_d)\n",
    "# \n",
    "# ## HebCup (First 1000)\n",
    "# print('HebCup (First 1000)')\n",
    "# hebcup_result = eval.evaluate('../result/baseline/HebCup_first1000.jsonl', 'HebCup')[:1000]\n",
    "# hebcup_d = evaluate(hebcup_result)\n",
    "# print_all_metrics(hebcup_d)\n",
    "\n",
    "# LLM\n",
    "def get_first_candidates(l: list, sorter) -> list:\n",
    "    return list(map(lambda x: sorter(x)[0], l))\n",
    "\n",
    "result = eval.evaluate('../result/candidates/candidates-20240328_154708.jsonl')\n",
    "\n",
    "count = len(result)\n",
    "\n",
    "print(f'LLM (First 1000)')\n",
    "\n",
    "print('> Top1:')\n",
    "simple_top1 = get_first_candidates(result, lambda x:x)\n",
    "d1 = evaluate(simple_top1)\n",
    "print_all_metrics(d1)\n",
    "\n",
    "print('> Optimal Top5:')\n",
    "theoretical_best = get_first_candidates(result,  lambda x: sort_by_evaluation_metric(x, 'gleu', True))\n",
    "d2 = evaluate(theoretical_best)\n",
    "print_all_metrics(d2)\n",
    "\n",
    "print('> Sort by rouge recall')\n",
    "rouge = get_first_candidates(result, lambda  x: sort_by_rouge(x, 'r'))\n",
    "print_all_metrics(evaluate(rouge))\n",
    "\n",
    "print('> Sort by rouge precision')\n",
    "rouge = get_first_candidates(result, lambda  x: sort_by_rouge(x, 'p'))\n",
    "print_all_metrics(evaluate(rouge))\n",
    "\n",
    "print('> Sort by rouge ƒ1')\n",
    "rouge = get_first_candidates(result, lambda  x: sort_by_rouge(x, 'f'))\n",
    "print_all_metrics(evaluate(rouge))\n",
    "\n",
    "print('> Sort by levenshtein distance')\n",
    "edd = get_first_candidates(result, lambda  x: sort_by_levenshtein_distance(x))\n",
    "print_all_metrics(evaluate(edd))\n",
    "\n",
    "print('> Sort by gleu')\n",
    "gleu = get_first_candidates(result, lambda  x: sort_by_gleu(x))\n",
    "print_all_metrics(evaluate(gleu))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
